{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:01.131246Z",
     "iopub.status.busy": "2025-05-12T20:00:01.130945Z",
     "iopub.status.idle": "2025-05-12T20:00:03.588118Z",
     "shell.execute_reply": "2025-05-12T20:00:03.587538Z",
     "shell.execute_reply.started": "2025-05-12T20:00:01.131219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "from huggingface_hub import notebook_login\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:03.589680Z",
     "iopub.status.busy": "2025-05-12T20:00:03.589206Z",
     "iopub.status.idle": "2025-05-12T20:00:12.697155Z",
     "shell.execute_reply": "2025-05-12T20:00:12.696516Z",
     "shell.execute_reply.started": "2025-05-12T20:00:03.589652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset('billsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:12.698812Z",
     "iopub.status.busy": "2025-05-12T20:00:12.698060Z",
     "iopub.status.idle": "2025-05-12T20:00:12.703255Z",
     "shell.execute_reply": "2025-05-12T20:00:12.702629Z",
     "shell.execute_reply.started": "2025-05-12T20:00:12.698786Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'summary', 'title'],\n",
      "        num_rows: 18949\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'summary', 'title'],\n",
      "        num_rows: 3269\n",
      "    })\n",
      "    ca_test: Dataset({\n",
      "        features: ['text', 'summary', 'title'],\n",
      "        num_rows: 1237\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:12.707442Z",
     "iopub.status.busy": "2025-05-12T20:00:12.706607Z",
     "iopub.status.idle": "2025-05-12T20:00:13.012328Z",
     "shell.execute_reply": "2025-05-12T20:00:13.011526Z",
     "shell.execute_reply.started": "2025-05-12T20:00:12.707419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "--------------------------------------------------\n",
      "SECTION 1. LIABILITY OF BUSINESS ENTITIES PROVIDING USE OF FACILITIES \n",
      "              TO NONPROFIT ORGANIZATIONS.\n",
      "\n",
      "    (a) Definitions.--In this section:\n",
      "            (1) Business entity.--The term ``business entity'' means a \n",
      "        firm, corporation, association, partnership, consortium, joint \n",
      "        venture, or other form of enterprise.\n",
      "            (2) Facility.--The term ``facility'' means any real \n",
      "        property, including any building, improvement, or appurtenance.\n",
      "            (3) Gross negligence.--The term ``gross negligence'' means \n",
      "        voluntary and conscious conduct by a person with knowledge (at \n",
      "        the time of the conduct) that the conduct is likely to be \n",
      "        harmful to the health or well-being of another person.\n",
      "            (4) Intentional misconduct.--The term ``intentional \n",
      "        misconduct'' means conduct by a person with knowledge (at the \n",
      "        time of the conduct) that the conduct is harmful to the health \n",
      "        or well-being of another person.\n",
      "            (5) Nonprofit organization.--The term ``nonprofit \n",
      "        organization'' means--\n",
      "                    (A) any organization described in section 501(c)(3) \n",
      "                of the Internal Revenue Code of 1986 and exempt from \n",
      "                tax under section 501(a) of such Code; or\n",
      "                    (B) any not-for-profit organization organized and \n",
      "                conducted for public benefit and operated primarily for \n",
      "                charitable, civic, educational, religious, welfare, or \n",
      "                health purposes.\n",
      "            (6) State.--The term ``State'' means each of the several \n",
      "        States, the District of Columbia, the Commonwealth of Puerto \n",
      "        Rico, the Virgin Islands, Guam, American Samoa, the Northern \n",
      "        Mariana Islands, any other territory or possession of the \n",
      "        United States, or any political subdivision of any such State, \n",
      "        territory, or possession.\n",
      "    (b) Limitation on Liability.--\n",
      "            (1) In general.--Subject to subsection (c), a business \n",
      "        entity shall not be subject to civil liability relating to any \n",
      "        injury or death occurring at a facility of the business entity \n",
      "        in connection with a use of such facility by a nonprofit \n",
      "        organization if--\n",
      "                    (A) the use occurs outside of the scope of business \n",
      "                of the business entity;\n",
      "                    (B) such injury or death occurs during a period \n",
      "                that such facility is used by the nonprofit \n",
      "                organization; and\n",
      "                    (C) the business entity authorized the use of such \n",
      "                facility by the nonprofit organization.\n",
      "            (2) Application.--This subsection shall apply--\n",
      "                    (A) with respect to civil liability under Federal \n",
      "                and State law; and\n",
      "                    (B) regardless of whether a nonprofit organization \n",
      "                pays for the use of a facility.\n",
      "    (c) Exception for Liability.--Subsection (b) shall not apply to an \n",
      "injury or death that results from an act or omission of a business \n",
      "entity that constitutes gross negligence or intentional misconduct, \n",
      "including any misconduct that--\n",
      "            (1) constitutes a crime of violence (as that term is \n",
      "        defined in section 16 of title 18, United States Code) or act \n",
      "        of international terrorism (as that term is defined in section \n",
      "        2331 of title 18) for which the defendant has been convicted in \n",
      "        any court;\n",
      "            (2) constitutes a hate crime (as that term is used in the \n",
      "        Hate Crime Statistics Act (28 U.S.C. 534 note));\n",
      "            (3) involves a sexual offense, as defined by applicable \n",
      "        State law, for which the defendant has been convicted in any \n",
      "        court; or\n",
      "            (4) involves misconduct for which the defendant has been \n",
      "        found to have violated a Federal or State civil rights law.\n",
      "    (d) Superseding Provision.--\n",
      "            (1) In general.--Subject to paragraph (2) and subsection \n",
      "        (e), this Act preempts the laws of any State to the extent that \n",
      "        such laws are inconsistent with this Act, except that this Act \n",
      "        shall not preempt any State law that provides additional \n",
      "        protection from liability for a business entity for an injury \n",
      "        or death with respect to which conditions under subparagraphs \n",
      "        (A) through (C) of subsection (b)(1) apply.\n",
      "            (2) Limitation.--Nothing in this Act shall be construed to \n",
      "        supersede any Federal or State health or safety law.\n",
      "    (e) Election of State Regarding Nonapplicability.--This Act shall \n",
      "not apply to any civil action in a State court against a business \n",
      "entity in which all parties are citizens of the State if such State \n",
      "enacts a statute--\n",
      "            (1) citing the authority of this subsection;\n",
      "            (2) declaring the election of such State that this Act \n",
      "        shall not apply to such civil action in the State; and\n",
      "            (3) containing no other provision.\n",
      "summary\n",
      "--------------------------------------------------\n",
      "Shields a business entity from civil liability relating to any injury or death occurring at a facility of that entity in connection with a use of such facility by a nonprofit organization if: (1) the use occurs outside the scope of business of the business entity; (2) such injury or death occurs during a period that such facility is used by such organization; and (3) the business entity authorized the use of such facility by the organization. \n",
      "Makes this Act inapplicable to an injury or death that results from an act or omission of a business entity that constitutes gross negligence or intentional misconduct, including misconduct that: (1) constitutes a hate crime or a crime of violence or act of international terrorism for which the defendant has been convicted in any court; or (2) involves a sexual offense for which the defendant has been convicted in any court or misconduct for which the defendant has been found to have violated a Federal or State civil rights law. \n",
      "Preempts State laws to the extent that such laws are inconsistent with this Act, except State law that provides additional protection from liability.  Specifies that this Act shall not be construed to supersede any Federal or State health or safety law. \n",
      "Makes this Act inapplicable to any civil action in a State court against a business entity in which all parties are citizens of the State if such State, citing this Act's authority and containing no other provision, enacts a statute declaring the State's election that this Act shall not apply to such action in the State.\n"
     ]
    }
   ],
   "source": [
    "print(\"Text\")\n",
    "print(\"-\"*50)\n",
    "print(dataset['train']['text'][0])\n",
    "print(\"summary\")\n",
    "print(\"-\"*50)\n",
    "print(dataset['train']['summary'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:13.013408Z",
     "iopub.status.busy": "2025-05-12T20:00:13.013168Z",
     "iopub.status.idle": "2025-05-12T20:00:13.172276Z",
     "shell.execute_reply": "2025-05-12T20:00:13.171491Z",
     "shell.execute_reply.started": "2025-05-12T20:00:13.013388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "corpus = dataset['train']['text'] + dataset['train']['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:13.173462Z",
     "iopub.status.busy": "2025-05-12T20:00:13.173201Z",
     "iopub.status.idle": "2025-05-12T20:00:25.058451Z",
     "shell.execute_reply": "2025-05-12T20:00:25.057774Z",
     "shell.execute_reply.started": "2025-05-12T20:00:13.173439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "trainer = BpeTrainer(vocab_size=16000, special_tokens=[\"[UNK]\", \"[PAD]\", \"<EOS>\", \"<SOS>\"])\n",
    "\n",
    "tokenizer.train_from_iterator(corpus, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:25.059393Z",
     "iopub.status.busy": "2025-05-12T20:00:25.059176Z",
     "iopub.status.idle": "2025-05-12T20:00:25.069730Z",
     "shell.execute_reply": "2025-05-12T20:00:25.068932Z",
     "shell.execute_reply.started": "2025-05-12T20:00:25.059374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:25.071023Z",
     "iopub.status.busy": "2025-05-12T20:00:25.070733Z",
     "iopub.status.idle": "2025-05-12T20:00:25.081649Z",
     "shell.execute_reply": "2025-05-12T20:00:25.080800Z",
     "shell.execute_reply.started": "2025-05-12T20:00:25.070998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:00:25.082691Z",
     "iopub.status.busy": "2025-05-12T20:00:25.082400Z",
     "iopub.status.idle": "2025-05-12T20:00:25.093282Z",
     "shell.execute_reply": "2025-05-12T20:00:25.092698Z",
     "shell.execute_reply.started": "2025-05-12T20:00:25.082666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK]: 0\n",
      "[PAD]: 1\n",
      "<EOS>: 2\n",
      "<SOS>: 3\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"<EOS>\", \"<SOS>\"]\n",
    "\n",
    "for token in special_tokens:\n",
    "    token_id = tokenizer.token_to_id(token)\n",
    "    print(f\"{token}: {token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:45.683548Z",
     "iopub.status.busy": "2025-05-12T20:04:45.682974Z",
     "iopub.status.idle": "2025-05-12T20:04:45.689236Z",
     "shell.execute_reply": "2025-05-12T20:04:45.688367Z",
     "shell.execute_reply.started": "2025-05-12T20:04:45.683525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TextSummaryDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_input_len=1024, max_target_len=256):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_input_len = max_input_len\n",
    "        self.max_target_len = max_target_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "    \n",
    "        input_enc = self.tokenizer.encode(item['text']).ids[:self.max_input_len]\n",
    "        target_enc = self.tokenizer.encode(item['summary']).ids[:self.max_target_len]\n",
    "    \n",
    "        sos_id = self.tokenizer.token_to_id('<SOS>')\n",
    "        eos_id = self.tokenizer.token_to_id('<EOS>')\n",
    "    \n",
    "        target_enc = [sos_id] + target_enc + [eos_id]\n",
    "    \n",
    "        return torch.tensor(input_enc), torch.tensor(target_enc), len(input_enc), len(target_enc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initiate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:46.332410Z",
     "iopub.status.busy": "2025-05-12T20:04:46.331646Z",
     "iopub.status.idle": "2025-05-12T20:04:46.338399Z",
     "shell.execute_reply": "2025-05-12T20:04:46.337707Z",
     "shell.execute_reply.started": "2025-05-12T20:04:46.332382Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = TextSummaryDataset(dataset['train'].select(range(10000)), tokenizer)\n",
    "test_dataset = TextSummaryDataset(dataset['test'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:46.710176Z",
     "iopub.status.busy": "2025-05-12T20:04:46.709668Z",
     "iopub.status.idle": "2025-05-12T20:04:46.713536Z",
     "shell.execute_reply": "2025-05-12T20:04:46.712819Z",
     "shell.execute_reply.started": "2025-05-12T20:04:46.710153Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "label_pad_idx = -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:47.321735Z",
     "iopub.status.busy": "2025-05-12T20:04:47.321424Z",
     "iopub.status.idle": "2025-05-12T20:04:47.326795Z",
     "shell.execute_reply": "2025-05-12T20:04:47.325977Z",
     "shell.execute_reply.started": "2025-05-12T20:04:47.321712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    input_ids, labels, lengths_list, out_lengths = zip(*batch)\n",
    "\n",
    "    lengths = torch.tensor(lengths_list)\n",
    "    out_lengths = torch.tensor(out_lengths)\n",
    "    \n",
    "    lengths, idx = lengths.sort(descending=True)\n",
    "    input_ids = [input_ids[i] for i in idx]\n",
    "    labels = [labels[i] for i in idx]\n",
    "\n",
    "    padded_inputs = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.token_to_id('[PAD]'))\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=label_pad_idx)  \n",
    "\n",
    "    return padded_inputs, padded_labels, lengths, out_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:47.480551Z",
     "iopub.status.busy": "2025-05-12T20:04:47.480137Z",
     "iopub.status.idle": "2025-05-12T20:04:47.483980Z",
     "shell.execute_reply": "2025-05-12T20:04:47.483354Z",
     "shell.execute_reply.started": "2025-05-12T20:04:47.480532Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:49.638890Z",
     "iopub.status.busy": "2025-05-12T20:04:49.638369Z",
     "iopub.status.idle": "2025-05-12T20:04:49.644554Z",
     "shell.execute_reply": "2025-05-12T20:04:49.643893Z",
     "shell.execute_reply.started": "2025-05-12T20:04:49.638866Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedd_dim, vocab_size, hidden_dim, num_layers, bidirectional, dropout, pad_indx):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.embd = nn.Embedding(vocab_size, embedd_dim, pad_indx)\n",
    "        self.lstm = nn.LSTM(input_size=embedd_dim, hidden_size=hidden_dim, \n",
    "                            num_layers=num_layers, bidirectional=bidirectional, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "        \n",
    "    def forward(self, text, lengths):\n",
    "        embed = self.embd(text)\n",
    "        packed_input = pack_padded_sequence(embed, lengths, batch_first=True)\n",
    "        packed_output, (hidden, cell) = self.lstm(packed_input) \n",
    "        if self.bidirectional:\n",
    "            hidden, cell = torch.cat((hidden[0: self.num_layers], hidden[self.num_layers:]), dim=2), torch.cat((cell[0: self.num_layers], cell[self.num_layers:]), dim=2)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:49.842973Z",
     "iopub.status.busy": "2025-05-12T20:04:49.842762Z",
     "iopub.status.idle": "2025-05-12T20:04:49.848206Z",
     "shell.execute_reply": "2025-05-12T20:04:49.847243Z",
     "shell.execute_reply.started": "2025-05-12T20:04:49.842957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embedd_dim, vocab_size, enc_dim, num_layers, dropout, pad_indx):\n",
    "        super().__init__()\n",
    "        self.embd = nn.Embedding(vocab_size, embedd_dim, pad_indx)\n",
    "        self.lstm = nn.LSTM(input_size=embedd_dim, hidden_size=enc_dim, \n",
    "                            num_layers=num_layers, \n",
    "                            dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(enc_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, text, hidden, cell):\n",
    "        embed = self.embd(text)\n",
    "        output, (hidden, cell) = self.lstm(embed, (hidden, cell)) \n",
    "        output = self.fc(output)\n",
    "        return output, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:49.982049Z",
     "iopub.status.busy": "2025-05-12T20:04:49.981511Z",
     "iopub.status.idle": "2025-05-12T20:04:49.987396Z",
     "shell.execute_reply": "2025-05-12T20:04:49.986505Z",
     "shell.execute_reply.started": "2025-05-12T20:04:49.982032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Summarizer(nn.Module):\n",
    "    def __init__(self, embedd_dim, vocab_size, hidden_dim, num_layers, bidirectional, dropout, pad_indx):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(embedd_dim, vocab_size, hidden_dim, num_layers, bidirectional, dropout, pad_indx)\n",
    "        self.enc_dim = 2 * hidden_dim if bidirectional else hidden_dim\n",
    "        self.decoder = Decoder(embedd_dim, vocab_size, self.enc_dim, num_layers, dropout, pad_indx)\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def forward(self, text, summary, lengths):\n",
    "        batch_size, tgt_len = summary.shape\n",
    "        outputs = torch.zeros((batch_size, tgt_len, self.vocab_size), device=text.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(text, lengths)\n",
    "        input_token = summary[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            output, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t, :] = output.squeeze(1)\n",
    "            input_token = output.argmax(2)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:52.143009Z",
     "iopub.status.busy": "2025-05-12T20:04:52.142410Z",
     "iopub.status.idle": "2025-05-12T20:04:52.149985Z",
     "shell.execute_reply": "2025-05-12T20:04:52.149307Z",
     "shell.execute_reply.started": "2025-05-12T20:04:52.142984Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def training_loop(model, dataloader, optimizer, criterion, epochs, device, label_pad_idx):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_tokens = 0\n",
    "\n",
    "        progress_bar = tqdm.tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "        for inputs, labels, lengths, lengths_label in progress_bar:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            lengths = lengths.to(\"cpu\") \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs, labels, lengths) \n",
    "\n",
    "            target = labels[:, 1:]  \n",
    "            output = outputs[:, 1:]\n",
    "\n",
    "            loss = criterion(output.contiguous().view(-1, output.shape[-1]), target.contiguous().view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * target.numel()\n",
    "\n",
    "            preds = torch.argmax(output, dim=2)\n",
    "            mask = target != label_pad_idx\n",
    "            total_correct += ((preds == target) & mask).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "            avg_batch_loss = running_loss / total_tokens\n",
    "            batch_accuracy = total_correct / total_tokens\n",
    "            progress_bar.set_postfix(loss=f\"{avg_batch_loss:.4f}\", acc=f\"{batch_accuracy:.4f}\")\n",
    "\n",
    "        epoch_loss = running_loss / total_tokens\n",
    "        epoch_accuracy = total_correct / total_tokens\n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_accuracy)\n",
    "\n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:04:52.605098Z",
     "iopub.status.busy": "2025-05-12T20:04:52.604637Z",
     "iopub.status.idle": "2025-05-12T20:04:52.608880Z",
     "shell.execute_reply": "2025-05-12T20:04:52.608167Z",
     "shell.execute_reply.started": "2025-05-12T20:04:52.605079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedd_dim = 500\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "bidirectional = True\n",
    "dropout = 0.5\n",
    "pad_indx = tokenizer.token_to_id('[PAD]')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T20:43:51.042079Z",
     "iopub.status.busy": "2025-05-12T20:43:51.041776Z",
     "iopub.status.idle": "2025-05-12T20:43:51.278434Z",
     "shell.execute_reply": "2025-05-12T20:43:51.277837Z",
     "shell.execute_reply.started": "2025-05-12T20:43:51.042056Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "summarizer = Summarizer(embedd_dim, vocab_size, hidden_dim, num_layers, bidirectional, dropout, pad_indx).to(device)\n",
    "optimizer = torch.optim.Adam(summarizer.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=label_pad_idx)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-12T22:14:01.689Z",
     "iopub.execute_input": "2025-05-12T20:43:52.482468Z",
     "iopub.status.busy": "2025-05-12T20:43:52.482200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "losses, accuracies =  training_loop(summarizer, train_loader, optimizer, criterion, epochs, device, label_pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-05-12T22:14:01.729Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def inference_loop(model, data_loader, tokenizer, label_pad_idx, device, max_examples=2):\n",
    "    model.eval()\n",
    "    examples_shown = 0\n",
    "    total_correct = 0\n",
    "    total_tokens = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels, lengths, lengths_label in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, lengths)\n",
    "\n",
    "            target = labels[:, 1:]  # Assuming <SOS> at position 0\n",
    "            output = outputs[:, 1:]\n",
    "\n",
    "            preds = torch.argmax(output, dim=2)\n",
    "            mask = target != label_pad_idx\n",
    "            total_correct += ((preds == target) & mask).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "\n",
    "            if examples_shown < max_examples:\n",
    "                for i in range(len(labels)):\n",
    "                    pred_ids = preds[i]\n",
    "                    true_ids = target[i]  # skip <SOS>\n",
    "\n",
    "                    # Filter out padding (-100)\n",
    "                    pred_filtered = pred_ids[true_ids != label_pad_idx].tolist()\n",
    "                    true_filtered = true_ids[true_ids != label_pad_idx].tolist()\n",
    "\n",
    "                    print(f\"[Example {examples_shown + 1}]\")\n",
    "                    print(\"Prediction   :\", tokenizer.decode(pred_filtered))\n",
    "                    print(\"Ground Truth :\", tokenizer.decode(true_filtered))\n",
    "                    print(\"-\" * 40)\n",
    "\n",
    "                    examples_shown += 1\n",
    "                    if examples_shown >= max_examples:\n",
    "                        break\n",
    "\n",
    "    accuracy = total_correct / total_tokens if total_tokens > 0 else 0\n",
    "    print(f\"Inference Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-12T20:43:47.617530Z",
     "iopub.status.idle": "2025-05-12T20:43:47.617778Z",
     "shell.execute_reply": "2025-05-12T20:43:47.617683Z",
     "shell.execute_reply.started": "2025-05-12T20:43:47.617672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "accuracy = inference_loop(summarizer, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
